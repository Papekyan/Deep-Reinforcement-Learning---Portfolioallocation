{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3f94bc0",
   "metadata": {
    "papermill": {
     "duration": 0.005371,
     "end_time": "2025-12-25T11:13:29.116393",
     "exception": false,
     "start_time": "2025-12-25T11:13:29.111022",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Deep Reinforcement Learning für die dynamische Portfolioallokation: Methoden, Chancen und Grenzen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab08b15",
   "metadata": {
    "papermill": {
     "duration": 0.004077,
     "end_time": "2025-12-25T11:13:29.125025",
     "exception": false,
     "start_time": "2025-12-25T11:13:29.120948",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Installieren und Importieren benötigter Pakete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4fea0b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-25T11:13:29.134120Z",
     "iopub.status.busy": "2025-12-25T11:13:29.133908Z",
     "iopub.status.idle": "2025-12-25T11:13:29.140002Z",
     "shell.execute_reply": "2025-12-25T11:13:29.139326Z"
    },
    "papermill": {
     "duration": 0.011978,
     "end_time": "2025-12-25T11:13:29.141111",
     "exception": false,
     "start_time": "2025-12-25T11:13:29.129133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "if not hasattr(np, 'float'):\n",
    "    np.float = float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307fb392",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T11:13:29.150103Z",
     "iopub.status.busy": "2025-12-25T11:13:29.149921Z",
     "iopub.status.idle": "2025-12-25T11:15:38.270023Z",
     "shell.execute_reply": "2025-12-25T11:15:38.269024Z"
    },
    "papermill": {
     "duration": 129.126761,
     "end_time": "2025-12-25T11:15:38.271918",
     "exception": false,
     "start_time": "2025-12-25T11:13:29.145157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "!pip install swig\n",
    "\n",
    "# FinRL und Finanz-Daten\n",
    "!pip install finrl\n",
    "!pip install yfinance\n",
    "!pip install wrds\n",
    "\n",
    "# Reinforcement Learning\n",
    "!pip install stable-baselines3\n",
    "!pip install shimmy>=0.2.1 \n",
    "!pip install gymnasium\n",
    "\n",
    "# Portfolio-Optimierung (Markowitz Baseline)\n",
    "!pip install pyportfolioopt\n",
    "\n",
    "# Hyperparameter Tuning \n",
    "!pip install optuna\n",
    "\n",
    "# Standard Data Science\n",
    "!pip install pandas numpy matplotlib\n",
    "!pip install protobuf==3.20.3\n",
    "\n",
    "# FinRL \n",
    "!pip install finrl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581d84a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T11:15:38.325278Z",
     "iopub.status.busy": "2025-12-25T11:15:38.325028Z",
     "iopub.status.idle": "2025-12-25T11:17:13.985478Z",
     "shell.execute_reply": "2025-12-25T11:17:13.984670Z"
    },
    "papermill": {
     "duration": 95.688221,
     "end_time": "2025-12-25T11:17:13.986669",
     "exception": false,
     "start_time": "2025-12-25T11:15:38.298448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "%pip install -q \"git+https://github.com/AI4Finance-Foundation/FinRL.git@master\" ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9c8791",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T11:17:14.044972Z",
     "iopub.status.busy": "2025-12-25T11:17:14.044728Z",
     "iopub.status.idle": "2025-12-25T11:17:46.947711Z",
     "shell.execute_reply": "2025-12-25T11:17:46.946877Z"
    },
    "papermill": {
     "duration": 32.933748,
     "end_time": "2025-12-25T11:17:46.949112",
     "exception": false,
     "start_time": "2025-12-25T11:17:14.015364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Basisimporte und Verzeichnisse vorbereiten (Kommentare auf Deutsch)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from finrl import config\n",
    "from finrl.config import INDICATORS\n",
    "\n",
    "\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import data_split\n",
    "\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer\n",
    "from finrl.plot import convert_daily_return_to_pyfolio_ts\n",
    "\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import risk_models, expected_returns\n",
    "\n",
    "from pyfolio import timeseries\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import MedianPruner\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc27871",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T11:17:47.008980Z",
     "iopub.status.busy": "2025-12-25T11:17:47.008440Z",
     "iopub.status.idle": "2025-12-25T11:17:47.020387Z",
     "shell.execute_reply": "2025-12-25T11:17:47.019869Z"
    },
    "papermill": {
     "duration": 0.042545,
     "end_time": "2025-12-25T11:17:47.021469",
     "exception": false,
     "start_time": "2025-12-25T11:17:46.978924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from stable_baselines3.common.utils import set_random_seed\n",
    "\n",
    "# WICHTIG: Einmal setzen, bevor irgendwelche Environments oder Modelle erstellt werden!\n",
    "MY_SEED = 42\n",
    "set_random_seed(MY_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78928e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T11:17:47.079079Z",
     "iopub.status.busy": "2025-12-25T11:17:47.078872Z",
     "iopub.status.idle": "2025-12-25T11:17:47.083566Z",
     "shell.execute_reply": "2025-12-25T11:17:47.083067Z"
    },
    "papermill": {
     "duration": 0.034795,
     "end_time": "2025-12-25T11:17:47.084663",
     "exception": false,
     "start_time": "2025-12-25T11:17:47.049868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR): os.makedirs(\"./\" + config.DATA_SAVE_DIR) \n",
    "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR): os.makedirs(\"./\" + config.TRAINED_MODEL_DIR) \n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR): os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR): os.makedirs(\"./\" + config.RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9629ca34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T18:13:32.570638Z",
     "iopub.status.busy": "2025-11-30T18:13:32.569931Z",
     "iopub.status.idle": "2025-11-30T18:13:32.574484Z",
     "shell.execute_reply": "2025-11-30T18:13:32.573814Z",
     "shell.execute_reply.started": "2025-11-30T18:13:32.570611Z"
    },
    "papermill": {
     "duration": 0.028333,
     "end_time": "2025-12-25T11:17:47.141459",
     "exception": false,
     "start_time": "2025-12-25T11:17:47.113126",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Download DJI, Festlegung von Umgebungsparamtern und Zeiträumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bc5d1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T11:17:47.199572Z",
     "iopub.status.busy": "2025-12-25T11:17:47.199368Z",
     "iopub.status.idle": "2025-12-25T11:17:47.202976Z",
     "shell.execute_reply": "2025-12-25T11:17:47.202419Z"
    },
    "papermill": {
     "duration": 0.03399,
     "end_time": "2025-12-25T11:17:47.204096",
     "exception": false,
     "start_time": "2025-12-25T11:17:47.170106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DOW_30_TICKER = [\n",
    "    'AAPL', 'AMGN', 'AMZN', 'AXP', 'BA', 'CAT', 'CRM', 'CSCO', 'CVX', 'DIS', \n",
    "    'GS', 'HD', 'HON', 'IBM', 'JNJ', 'JPM', 'KO', 'MCD', 'MMM', 'MRK', \n",
    "    'MSFT', 'NKE', 'NVDA', 'PG', 'SHW', 'TRV', 'UNH', 'V', 'VZ', 'WMT'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be396dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T11:17:47.263892Z",
     "iopub.status.busy": "2025-12-25T11:17:47.263597Z",
     "iopub.status.idle": "2025-12-25T11:17:47.267337Z",
     "shell.execute_reply": "2025-12-25T11:17:47.266843Z"
    },
    "papermill": {
     "duration": 0.035987,
     "end_time": "2025-12-25T11:17:47.268385",
     "exception": false,
     "start_time": "2025-12-25T11:17:47.232398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dow-Jones-Konfiguration und Trainings-/Testzeiträume (Kommentare auf Deutsch)\n",
    "ticker_list = DOW_30_TICKER\n",
    "\n",
    "\n",
    "train_start_date = \"2010-01-01\"\n",
    "train_end_date = \"2020-12-31\"\n",
    "\n",
    "validate_start_date = \"2021-01-01\"\n",
    "validate_end_date = \"2022-12-31\"  # Validierung inkl. COVID + 2022-Crash\n",
    "\n",
    "trade_start_date = \"2023-01-01\"  # Test beginnt nach dem Crash\n",
    "trade_end_date = \"2025-11-01\"\n",
    "\n",
    "initial_capital = 1000000\n",
    "transaction_cost_pct = 0.001  # 10 Basispunkte pro Trade\n",
    "hmax = 10000  # maximale Stückzahl pro Order\n",
    "reward_scaling = 1e-4  \n",
    "num_stock_shares = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9286f658",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T11:17:47.326096Z",
     "iopub.status.busy": "2025-12-25T11:17:47.325903Z",
     "iopub.status.idle": "2025-12-25T11:18:05.795882Z",
     "shell.execute_reply": "2025-12-25T11:18:05.795005Z"
    },
    "papermill": {
     "duration": 18.500424,
     "end_time": "2025-12-25T11:18:05.797360",
     "exception": false,
     "start_time": "2025-12-25T11:17:47.296936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_raw = YahooDownloader(\n",
    "    start_date=train_start_date,\n",
    "    end_date=trade_end_date,\n",
    "    ticker_list= DOW_30_TICKER,\n",
    ").fetch_data()\n",
    "df_raw.to_csv('dow_30_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81e2676",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T11:18:05.862006Z",
     "iopub.status.busy": "2025-12-25T11:18:05.861423Z",
     "iopub.status.idle": "2025-12-25T11:18:05.881860Z",
     "shell.execute_reply": "2025-12-25T11:18:05.881102Z"
    },
    "papermill": {
     "duration": 0.053354,
     "end_time": "2025-12-25T11:18:05.883011",
     "exception": false,
     "start_time": "2025-12-25T11:18:05.829657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_raw\n",
    "\n",
    "df_raw.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2561ce",
   "metadata": {
    "papermill": {
     "duration": 0.031313,
     "end_time": "2025-12-25T11:18:05.945691",
     "exception": false,
     "start_time": "2025-12-25T11:18:05.914378",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Datenverarbeitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac74ecbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T11:18:06.009062Z",
     "iopub.status.busy": "2025-12-25T11:18:06.008868Z",
     "iopub.status.idle": "2025-12-25T11:19:22.680413Z",
     "shell.execute_reply": "2025-12-25T11:19:22.679709Z"
    },
    "papermill": {
     "duration": 76.736839,
     "end_time": "2025-12-25T11:19:22.713805",
     "exception": false,
     "start_time": "2025-12-25T11:18:05.976966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fe = FeatureEngineer(\n",
    "    use_technical_indicator=True,\n",
    "    use_vix=True,        \n",
    "    use_turbulence=True,  \n",
    "    user_defined_feature=False\n",
    ")\n",
    "df = fe.preprocess_data(df_raw)\n",
    "\n",
    "df=df.sort_values(['date','tic'],ignore_index=True)\n",
    "df.index = df.date.factorize()[0]\n",
    "\n",
    "cov_list = []\n",
    "return_list = []\n",
    "\n",
    "\n",
    "lookback=252\n",
    "for i in range(lookback,len(df.index.unique())):\n",
    "  data_lookback = df.loc[i-lookback:i,:]\n",
    "  price_lookback=data_lookback.pivot_table(index = 'date',columns = 'tic', values = 'close')\n",
    "  return_lookback = price_lookback.pct_change().dropna()\n",
    "  return_list.append(return_lookback)\n",
    "\n",
    "  covs = return_lookback.cov().values \n",
    "  cov_list.append(covs)\n",
    "\n",
    "  \n",
    "df_cov = pd.DataFrame({'date':df.date.unique()[lookback:],'cov_list':cov_list,'return_list':return_list})\n",
    "df = df.merge(df_cov, on='date')\n",
    "df = df.sort_values(['date','tic']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376ea293",
   "metadata": {
    "papermill": {
     "duration": 0.106691,
     "end_time": "2025-12-25T11:19:22.852401",
     "exception": false,
     "start_time": "2025-12-25T11:19:22.745710",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. Erstellung der Umgebungen für Training, Validierung und Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2b31dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T11:19:22.917402Z",
     "iopub.status.busy": "2025-12-25T11:19:22.916777Z",
     "iopub.status.idle": "2025-12-25T11:19:22.926010Z",
     "shell.execute_reply": "2025-12-25T11:19:22.925114Z"
    },
    "papermill": {
     "duration": 0.043157,
     "end_time": "2025-12-25T11:19:22.927100",
     "exception": false,
     "start_time": "2025-12-25T11:19:22.883943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stock_dim = len(df.tic.unique())\n",
    "\n",
    "print(f\"State-Dimension: {stock_dim} | Aktienanzahl: {stock_dim}\")\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": hmax,\n",
    "    \"initial_amount\": initial_capital,\n",
    "    \"transaction_cost_pct\": transaction_cost_pct,\n",
    "    \"state_space\": stock_dim,\n",
    "    \"stock_dim\": stock_dim,\n",
    "    \"tech_indicator_list\": INDICATORS,\n",
    "    \"action_space\": stock_dim,\n",
    "    \"reward_scaling\": reward_scaling,\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b47aea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T11:19:22.992946Z",
     "iopub.status.busy": "2025-12-25T11:19:22.992723Z",
     "iopub.status.idle": "2025-12-25T11:19:23.104533Z",
     "shell.execute_reply": "2025-12-25T11:19:23.103952Z"
    },
    "papermill": {
     "duration": 0.146575,
     "end_time": "2025-12-25T11:19:23.105844",
     "exception": false,
     "start_time": "2025-12-25T11:19:22.959269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = data_split(df,train_start_date,train_end_date) \n",
    "validate = data_split(df,validate_start_date, validate_end_date) \n",
    "test = data_split(df,validate_start_date, trade_end_date) \n",
    "test_opt = data_split(df,trade_start_date, trade_end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb7e061",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T11:19:23.174188Z",
     "iopub.status.busy": "2025-12-25T11:19:23.173960Z",
     "iopub.status.idle": "2025-12-25T11:19:23.194055Z",
     "shell.execute_reply": "2025-12-25T11:19:23.193313Z"
    },
    "papermill": {
     "duration": 0.055501,
     "end_time": "2025-12-25T11:19:23.195219",
     "exception": false,
     "start_time": "2025-12-25T11:19:23.139718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import gymnasium as gym\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gymnasium import spaces\n",
    "from gymnasium.utils import seeding\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "class StockPortfolioEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    MODIFIZIERTE FinRL Portfolio Umgebung für die Bachelorarbeit.\n",
    "    \n",
    "    Erweiterungen:\n",
    "    1. Transaktionskosten werden nun mathematisch berücksichtigt (Abzug vom Portfoliowert).\n",
    "    2. Die Gewichtung des Vortages (w_{t-1}) ist nun Teil des State Space.\n",
    "    \"\"\"\n",
    "\n",
    "    metadata = {\"render.modes\": [\"human\"]}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        stock_dim,\n",
    "        hmax,\n",
    "        initial_amount,\n",
    "        transaction_cost_pct,\n",
    "        reward_scaling,\n",
    "        state_space,\n",
    "        action_space,\n",
    "        tech_indicator_list,\n",
    "        turbulence_threshold=None,\n",
    "        lookback=252,\n",
    "        day=0,\n",
    "    ):\n",
    "        self.day = day\n",
    "        self.lookback = lookback\n",
    "        self.df = df\n",
    "        self.stock_dim = stock_dim\n",
    "        self.hmax = hmax\n",
    "        self.initial_amount = initial_amount\n",
    "        self.transaction_cost_pct = transaction_cost_pct\n",
    "        self.reward_scaling = reward_scaling\n",
    "        self.state_space = state_space\n",
    "        self.action_space = action_space\n",
    "        self.tech_indicator_list = tech_indicator_list\n",
    "\n",
    "        # Action Space: Gewichte für alle Aktien (werden per Softmax normalisiert)\n",
    "        self.action_space = spaces.Box(low=0, high=1, shape=(self.action_space,))\n",
    "\n",
    "        # --- MODIFIKATION 1: State Space Erweiterung ---\n",
    "        # Wir fügen EINE Zeile hinzu (+1) für die Portfolio-Gewichte vom Vortag\n",
    "        # Shape: (Anzahl Features + 1 für Gewichte, Anzahl Aktien)\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf,\n",
    "            high=np.inf,\n",
    "            shape=(self.state_space + len(self.tech_indicator_list) + 1, self.state_space),\n",
    "        )\n",
    "\n",
    "        # Initiale Daten laden\n",
    "        self.data = self.df.loc[self.day, :]\n",
    "        self.covs = self.data[\"cov_list\"].values[0]\n",
    "        \n",
    "        # --- MODIFIKATION 2: Initiale Gewichte für den ersten State ---\n",
    "        # Zum Start (Tag 0) nehmen wir eine Gleichverteilung an (1/N)\n",
    "        self.last_weights = np.array([1/self.stock_dim] * self.stock_dim)\n",
    "        \n",
    "        # State bauen (ausgelagerte Funktion nutzen)\n",
    "        self.state = self._update_state()\n",
    "\n",
    "        self.terminal = False\n",
    "        self.turbulence_threshold = turbulence_threshold\n",
    "        self.portfolio_value = self.initial_amount\n",
    "\n",
    "        # Memory initialisieren\n",
    "        self.asset_memory = [self.initial_amount]\n",
    "        self.portfolio_return_memory = [0]\n",
    "        self.actions_memory = [self.last_weights] # Speichert die Start-Gewichte\n",
    "        self.date_memory = [self.data.date.unique()[0]]\n",
    "\n",
    "    def step(self, actions):\n",
    "        self.terminal = self.day >= len(self.df.index.unique()) - 1\n",
    "\n",
    "        if self.terminal:\n",
    "            # --- Plotting am Ende der Episode ---\n",
    "            df = pd.DataFrame(self.portfolio_return_memory)\n",
    "            df.columns = [\"daily_return\"]\n",
    "            plt.plot(df.daily_return.cumsum(), \"r\")\n",
    "            plt.savefig(\"results/cumulative_reward.png\")\n",
    "            plt.close()\n",
    "\n",
    "            plt.plot(self.portfolio_return_memory, \"r\")\n",
    "            plt.savefig(\"results/rewards.png\")\n",
    "            plt.close()\n",
    "\n",
    "            print(\"=================================\")\n",
    "            print(f\"begin_total_asset:{self.asset_memory[0]}\")\n",
    "            print(f\"end_total_asset:{self.portfolio_value}\")\n",
    "\n",
    "            df_daily_return = pd.DataFrame(self.portfolio_return_memory)\n",
    "            df_daily_return.columns = [\"daily_return\"]\n",
    "            if df_daily_return[\"daily_return\"].std() != 0:\n",
    "                sharpe = (\n",
    "                    (252**0.5)\n",
    "                    * df_daily_return[\"daily_return\"].mean()\n",
    "                    / df_daily_return[\"daily_return\"].std()\n",
    "                )\n",
    "                print(\"Sharpe: \", sharpe)\n",
    "            print(\"=================================\")\n",
    "\n",
    "            return self.state, self.reward, self.terminal, False, {}\n",
    "\n",
    "        else:\n",
    "            # 1. Aktionen (Logits) in Gewichte (Summe=1) umwandeln\n",
    "            weights = self.softmax_normalization(actions)\n",
    "            \n",
    "            # --- MODIFIKATION 3: Transaktionskosten berechnen ---\n",
    "            # Turnover = Summe der absoluten Änderungen der Gewichte\n",
    "            turnover = np.sum(np.abs(weights - self.last_weights)) \n",
    "            \n",
    "            # Kosten = Turnover * Kostenrate * Aktueller Portfoliowert\n",
    "            # (Annahme: Kosten fallen proportional zum gehandelten Volumen an)\n",
    "            transaction_cost = turnover * self.transaction_cost_pct * self.portfolio_value\n",
    "            \n",
    "            # Memory Update\n",
    "            self.actions_memory.append(weights)\n",
    "            self.last_weights = weights # Wichtig: Merken für nächsten Schritt!\n",
    "            \n",
    "            last_day_memory = self.data\n",
    "\n",
    "            # Zeit-Schritt: Einen Tag vorwärts\n",
    "            self.day += 1\n",
    "            self.data = self.df.loc[self.day, :]\n",
    "            \n",
    "            # 2. Portfolio Return berechnen (Brutto, nur Kursgewinne)\n",
    "            # Formel: Summe( (Preis_neu / Preis_alt - 1) * Gewicht )\n",
    "            raw_portfolio_return = sum(\n",
    "                ((self.data.close.values / last_day_memory.close.values) - 1) * weights\n",
    "            )\n",
    "            \n",
    "            # 3. Neuen Portfoliowert berechnen (MIT Kostenabzug)\n",
    "            # Wert_neu = (Wert_alt * (1 + Rendite)) - Kosten\n",
    "            new_portfolio_value = (self.portfolio_value * (1 + raw_portfolio_return)) - transaction_cost\n",
    "            \n",
    "            # Effektive Netto-Rendite berechnen\n",
    "            portfolio_return = (new_portfolio_value - self.portfolio_value) / self.portfolio_value\n",
    "            \n",
    "            self.portfolio_value = new_portfolio_value\n",
    "\n",
    "            # Memory speichern\n",
    "            self.portfolio_return_memory.append(portfolio_return)\n",
    "            self.date_memory.append(self.data.date.unique()[0])\n",
    "            self.asset_memory.append(new_portfolio_value)\n",
    "\n",
    "            # Reward setzen (hier: Neuer Portfoliowert)\n",
    "            self.reward = new_portfolio_value\n",
    "            # Alternativ für stabileres Training: self.reward = np.log(new_portfolio_value / self.asset_memory[-2])\n",
    "\n",
    "            # --- MODIFIKATION 4: State Update (mit neuen Gewichten) ---\n",
    "            self.covs = self.data[\"cov_list\"].values[0]\n",
    "            self.state = self._update_state()\n",
    "\n",
    "        return self.state, self.reward, self.terminal, False, {}\n",
    "\n",
    "    def reset(self, *, seed=None, options=None):\n",
    "        self.asset_memory = [self.initial_amount]\n",
    "        self.day = 0\n",
    "        self.data = self.df.loc[self.day, :]\n",
    "        \n",
    "        self.covs = self.data[\"cov_list\"].values[0]\n",
    "        \n",
    "        # Reset auf Gleichverteilung\n",
    "        self.last_weights = np.array([1/self.stock_dim] * self.stock_dim)\n",
    "        \n",
    "        # State bauen\n",
    "        self.state = self._update_state()\n",
    "        \n",
    "        self.portfolio_value = self.initial_amount\n",
    "        self.terminal = False\n",
    "        self.portfolio_return_memory = [0]\n",
    "        self.actions_memory = [self.last_weights]\n",
    "        self.date_memory = [self.data.date.unique()[0]]\n",
    "        return self.state, {}\n",
    "\n",
    "    def _update_state(self):\n",
    "        \"\"\"Hilfsfunktion: Baut den State-Tensor zusammen.\"\"\"\n",
    "        # 1. Tech Indicators holen\n",
    "        tech_data = [self.data[tech].values.tolist() for tech in self.tech_indicator_list]\n",
    "        \n",
    "        # 2. Alles stapeln: [Covariance, Tech Indicators, Last Weights]\n",
    "        # Wir nutzen np.append mit axis=0, um Zeilen anzufügen\n",
    "        new_state = np.append(\n",
    "            np.array(self.covs),\n",
    "            tech_data,\n",
    "            axis=0\n",
    "        )\n",
    "        # Die Gewichte als letzte Zeile anfügen\n",
    "        new_state = np.append(new_state, [self.last_weights], axis=0)\n",
    "        \n",
    "        return new_state\n",
    "\n",
    "    def render(self, mode=\"human\"):\n",
    "        return self.state\n",
    "\n",
    "    def softmax_normalization(self, actions):\n",
    "        numerator = np.exp(actions)\n",
    "        denominator = np.sum(np.exp(actions))\n",
    "        softmax_output = numerator / denominator\n",
    "        return softmax_output\n",
    "\n",
    "    def save_asset_memory(self):\n",
    "        date_list = self.date_memory\n",
    "        portfolio_return = self.portfolio_return_memory\n",
    "        df_account_value = pd.DataFrame(\n",
    "            {\"date\": date_list, \"daily_return\": portfolio_return}\n",
    "        )\n",
    "        return df_account_value\n",
    "\n",
    "    def save_action_memory(self):\n",
    "        date_list = self.date_memory\n",
    "        df_date = pd.DataFrame(date_list)\n",
    "        df_date.columns = [\"date\"]\n",
    "\n",
    "        action_list = self.actions_memory\n",
    "        df_actions = pd.DataFrame(action_list)\n",
    "        df_actions.columns = self.data.tic.values\n",
    "        df_actions.index = df_date.date\n",
    "        return df_actions\n",
    "\n",
    "    def _seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def get_sb_env(self):\n",
    "        e = DummyVecEnv([lambda: self])\n",
    "        obs = e.reset()\n",
    "        return e, obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e44268",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T11:19:23.259598Z",
     "iopub.status.busy": "2025-12-25T11:19:23.259105Z",
     "iopub.status.idle": "2025-12-25T11:19:23.267972Z",
     "shell.execute_reply": "2025-12-25T11:19:23.267463Z"
    },
    "papermill": {
     "duration": 0.042095,
     "end_time": "2025-12-25T11:19:23.268986",
     "exception": false,
     "start_time": "2025-12-25T11:19:23.226891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_env = StockPortfolioEnv(df = train, **env_kwargs )\n",
    "validate_env = StockPortfolioEnv(df = validate, **env_kwargs)\n",
    "test_env = StockPortfolioEnv(df = test, **env_kwargs)\n",
    "test_opt_env = StockPortfolioEnv(df = test_opt ,**env_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e115129e",
   "metadata": {
    "papermill": {
     "duration": 0.031266,
     "end_time": "2025-12-25T11:19:23.331932",
     "exception": false,
     "start_time": "2025-12-25T11:19:23.300666",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5.Agenten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd50184",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T11:19:23.395110Z",
     "iopub.status.busy": "2025-12-25T11:19:23.394922Z",
     "iopub.status.idle": "2025-12-25T11:50:12.709546Z",
     "shell.execute_reply": "2025-12-25T11:50:12.708525Z"
    },
    "papermill": {
     "duration": 1849.348255,
     "end_time": "2025-12-25T11:50:12.711189",
     "exception": false,
     "start_time": "2025-12-25T11:19:23.362934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent_train =DRLAgent(env = train_env)\n",
    "timesteps = 100000\n",
    "model_ppo = agent_train.get_model(model_name=\"ppo\")\n",
    "model_ddpg = agent_train.get_model(model_name=\"ddpg\")\n",
    "model_td3 = agent_train.get_model(model_name=\"td3\")\n",
    "\n",
    "\n",
    "trained_ppo = agent_train.train_model(model=model_ppo, tb_log_name='ppo',\n",
    "                                total_timesteps=timesteps)\n",
    "trained_ddpg= agent_train.train_model(model=model_ddpg, tb_log_name='ddpg',\n",
    "                                total_timesteps=timesteps)\n",
    "trained_td3 = agent_train.train_model(model=model_td3, tb_log_name='td3',\n",
    "                                total_timesteps=timesteps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0942e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T11:50:12.795787Z",
     "iopub.status.busy": "2025-12-25T11:50:12.794835Z",
     "iopub.status.idle": "2025-12-25T11:50:18.651251Z",
     "shell.execute_reply": "2025-12-25T11:50:18.650348Z"
    },
    "papermill": {
     "duration": 5.89981,
     "end_time": "2025-12-25T11:50:18.652592",
     "exception": false,
     "start_time": "2025-12-25T11:50:12.752782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_daily_return_ppo, df_actions_ppo = DRLAgent.DRL_prediction(model=trained_ppo, environment = test_env)\n",
    "\n",
    "df_daily_return_ddpg, df_actions_ddpg = DRLAgent.DRL_prediction(model=trained_ddpg, environment = test_env)\n",
    "\n",
    "df_daily_return_td3, df_actions_td3 = DRLAgent.DRL_prediction(model=trained_td3, environment = test_env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5c5a4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T11:50:18.741082Z",
     "iopub.status.busy": "2025-12-25T11:50:18.740510Z",
     "iopub.status.idle": "2025-12-25T11:50:18.914535Z",
     "shell.execute_reply": "2025-12-25T11:50:18.913967Z"
    },
    "papermill": {
     "duration": 0.218207,
     "end_time": "2025-12-25T11:50:18.915692",
     "exception": false,
     "start_time": "2025-12-25T11:50:18.697485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_daily_return_ppo.to_csv(\"results/ppo_performance.csv\", index=False)\n",
    "df_daily_return_ddpg.to_csv(\"results/ddpg__performance.csv\", index=False)\n",
    "df_daily_return_td3.to_csv(\"results/td3_performance.csv\", index=False)\n",
    "\n",
    "df_actions_ppo.to_csv(\"results/ppo_actions.csv\", index=False)\n",
    "df_actions_ddpg.to_csv(\"results/ddpg_actions.csv\", index=False)\n",
    "df_actions_td3.to_csv(\"results/td3_actions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508a1ab2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T11:50:18.999001Z",
     "iopub.status.busy": "2025-12-25T11:50:18.998528Z",
     "iopub.status.idle": "2025-12-25T11:50:22.556651Z",
     "shell.execute_reply": "2025-12-25T11:50:22.556015Z"
    },
    "papermill": {
     "duration": 3.601147,
     "end_time": "2025-12-25T11:50:22.558155",
     "exception": false,
     "start_time": "2025-12-25T11:50:18.957008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ppo_cumpod =(df_daily_return_ppo.daily_return+1).cumprod()-1\n",
    "ddpg_cumpod =(df_daily_return_ddpg.daily_return+1).cumprod()-1\n",
    "td3_cumpod =(df_daily_return_td3.daily_return+1).cumprod()-1\n",
    "\n",
    "DRL_strat_ppo = convert_daily_return_to_pyfolio_ts(df_daily_return_ppo)\n",
    "DRL_strat_ddpg = convert_daily_return_to_pyfolio_ts(df_daily_return_ddpg)\n",
    "DRL_strat_td3 = convert_daily_return_to_pyfolio_ts(df_daily_return_td3)\n",
    "\n",
    "\n",
    "perf_func = timeseries.perf_stats \n",
    "\n",
    "\n",
    "perf_stats_all_ppo = perf_func( returns=DRL_strat_ppo, factor_returns=DRL_strat_ppo, positions=None, transactions=None, turnover_denom=\"AGB\")\n",
    "\n",
    "perf_stats_all_ddpg = perf_func( returns=DRL_strat_ddpg, factor_returns=DRL_strat_ddpg, positions=None, transactions=None, turnover_denom=\"AGB\")\n",
    "\n",
    "perf_stats_all_td3 = perf_func( returns=DRL_strat_td3, factor_returns=DRL_strat_td3, positions=None, transactions=None, turnover_denom=\"AGB\")\n",
    "\n",
    "def extract_weights(drl_actions_list):\n",
    "  a2c_weight_df = {'date':[], 'weights':[]}\n",
    "  for i in range(len(drl_actions_list)):\n",
    "    date = drl_actions_list.index[i]\n",
    "    tic_list = list(drl_actions_list.columns)\n",
    "    weights_list = drl_actions_list.reset_index()[list(drl_actions_list.columns)].iloc[i].values\n",
    "    weight_dict = {'tic':[], 'weight':[]}\n",
    "    for j in range(len(tic_list)):\n",
    "      weight_dict['tic'] += [tic_list[j]]\n",
    "      weight_dict['weight'] += [weights_list[j]]\n",
    "\n",
    "    a2c_weight_df['date'] += [date]\n",
    "    a2c_weight_df['weights'] += [pd.DataFrame(weight_dict)]\n",
    "\n",
    "  a2c_weights = pd.DataFrame(a2c_weight_df)\n",
    "  return a2c_weights\n",
    "\n",
    "\n",
    "ppo_weights = extract_weights(df_actions_ppo)\n",
    "ddpg_weights = extract_weights(df_actions_ddpg)\n",
    "td3_weights = extract_weights(df_actions_td3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef553d7",
   "metadata": {
    "papermill": {
     "duration": 0.040528,
     "end_time": "2025-12-25T11:50:22.644572",
     "exception": false,
     "start_time": "2025-12-25T11:50:22.604044",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5.Tuning der Agenten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0d804d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from stable_baselines3 import PPO, DDPG, TD3\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "\n",
    "def objective(trial, agent_name, train_env, validation_env):\n",
    "    \n",
    "    policy_kwargs = dict(net_arch=[64, 64])\n",
    "\n",
    "    n_actions = train_env.action_space.shape[-1]\n",
    "\n",
    "    action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "\n",
    "    # HYPERPARAMETER \n",
    "    \n",
    "    if agent_name == \"ppo\":\n",
    "        params = {\n",
    "\n",
    "            \"n_steps\": trial.suggest_categorical(\"n_steps\", [2048, 4096, 8192]), \n",
    "            \"ent_coef\": trial.suggest_loguniform(\"ent_coef\", 1e-8, 0.01),        \n",
    "            \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-5, 5e-4),\n",
    "            \"batch_size\": trial.suggest_categorical(\"batch_size\", [64, 128, 256]),\n",
    "            \"gamma\": trial.suggest_categorical(\"gamma\", [0.99, 0.995, 0.999]), \n",
    "            \"clip_range\": trial.suggest_categorical(\"clip_range\", [0.1, 0.2, 0.3]),\n",
    "        }\n",
    "        model = PPO(\"MlpPolicy\", train_env, verbose=0, policy_kwargs=policy_kwargs, **params)\n",
    "    \n",
    "    # DPG Hyperparameter\n",
    "    elif agent_name == \"ddpg\":\n",
    "        params = {\n",
    "            \"buffer_size\": trial.suggest_categorical(\"buffer_size\", [50000, 100000, 200000]),\n",
    "            \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-3),\n",
    "            \"batch_size\": trial.suggest_categorical(\"batch_size\", [64, 128, 256]),\n",
    "            \"gamma\": trial.suggest_categorical(\"gamma\", [0.99, 0.995, 0.999]),\n",
    "            \"tau\": trial.suggest_categorical(\"tau\", [0.001, 0.005, 0.01, 0.02]),\n",
    "        }\n",
    "\n",
    "        model = DDPG(\"MlpPolicy\", train_env, action_noise=action_noise, verbose=0, policy_kwargs=policy_kwargs, **params)\n",
    "   \n",
    "    # TD3 Hyperparameter\n",
    "    elif agent_name == \"td3\":\n",
    "         params = {\n",
    "            \"buffer_size\": trial.suggest_categorical(\"buffer_size\", [50000, 100000, 200000]),\n",
    "            \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-3),\n",
    "            \"batch_size\": trial.suggest_categorical(\"batch_size\", [64, 128, 256]),\n",
    "            \"gamma\": trial.suggest_categorical(\"gamma\", [0.99, 0.995, 0.999]),\n",
    "            \"tau\": trial.suggest_categorical(\"tau\", [0.001, 0.005, 0.01, 0.02]),\n",
    "        }\n",
    "\n",
    "         model = TD3(\"MlpPolicy\", train_env, action_noise=action_noise, verbose=0, policy_kwargs=policy_kwargs, **params)\n",
    "\n",
    "\n",
    "    try:\n",
    "        model.learn(total_timesteps=100000)\n",
    "    except:\n",
    "        return -9999.0\n",
    "\n",
    "    obs = validation_env.reset()\n",
    "    if isinstance(obs, tuple): obs = obs[0]\n",
    "\n",
    "    portfolio_values = [] \n",
    "    \n",
    "    done = False\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        step_result = validation_env.step(action)\n",
    "        \n",
    "        if len(step_result) == 5:\n",
    "            obs, reward, terminal, truncated, info = step_result\n",
    "            done = terminal or truncated\n",
    "        elif len(step_result) == 4:\n",
    "            obs, reward, done, info = step_result\n",
    "        else:\n",
    "            obs, reward, dones, info = step_result\n",
    "            done = dones[0]\n",
    "            \n",
    "\n",
    "        if isinstance(reward, (list, np.ndarray)):\n",
    "            val = reward[0]\n",
    "        else:\n",
    "            val = reward\n",
    "        portfolio_values.append(val)\n",
    "\n",
    "\n",
    "    if len(portfolio_values) < 2: return -9999.0\n",
    "    \n",
    "\n",
    "    df_values = pd.Series(portfolio_values)\n",
    "    daily_returns = df_values.pct_change().dropna()\n",
    "    \n",
    "\n",
    "    if daily_returns.empty or daily_returns.std() == 0:\n",
    "        return -9999.0\n",
    "        \n",
    "    std_dev = daily_returns.std()\n",
    "    mean_return = daily_returns.mean()\n",
    "    \n",
    "\n",
    "    sharpe = (252**0.5) * mean_return / std_dev\n",
    "    \n",
    "\n",
    "    if np.isnan(sharpe) or np.isinf(sharpe):\n",
    "        return -9999.0\n",
    "        \n",
    "    return sharpe\n",
    "\n",
    "\n",
    "\n",
    "def tune_agent(agent_name, train_data, val_data, n_trials=20):\n",
    "    env_train_opt,_ = StockPortfolioEnv(df=train_data, **env_kwargs).get_sb_env()\n",
    "    env_val,_ = StockPortfolioEnv(df=val_data, **env_kwargs).get_sb_env()\n",
    "\n",
    "    # Optuna Study\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    \n",
    "    # Lambda-Funktion\n",
    "    study.optimize(lambda trial: objective(trial, agent_name, env_train_opt, env_val), n_trials=n_trials)\n",
    "    \n",

    "    return study.best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93387363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A) DDPG Tunen \n",
    "print(\"\\n--- Start Tuning DDPG ---\")\n",
    "best_params_ddpg = tune_agent(\"ddpg\", train, validate, n_trials=35)\n",
    "\n",
    "#B) PPO Tunen\n",
    "print(\"\\n--- Start Tuning PPO ---\")\n",
    "best_params_ppo = tune_agent(\"ppo\", train, validate, n_trials=35)\n",
    "\n",
    "\n",
    "#C) TD3 Tunen\n",
    "print(\"\\n--- Start Tuning TD3 ---\")\n",
    "best_params_td3 = tune_agent(\"td3\", train, validate, n_trials=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39363ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 100000\n",
    "agent = DRLAgent(env=train_env)\n",
    "\n",
    "\n",
    "model_ddpg_opt = agent.get_model(\"ddpg\", model_kwargs=best_params_ddpg) \n",
    "trained_ddpg_opt = agent.train_model(model=model_ddpg_opt, tb_log_name='ddpg',\n",
    "                                total_timesteps=timesteps)\n",
    "\n",
    "\n",
    "model_ppo_opt = agent.get_model(\"ppo\", model_kwargs=best_params_ppo) \n",
    "trained_ppo_opt = agent.train_model(model=model_ppo_opt, tb_log_name='ppo',\n",
    "                                total_timesteps=timesteps)\n",
    "\n",
    "\n",
    "model_td3_opt = agent.get_model(\"td3\", model_kwargs=best_params_td3) \n",
    "trained_td3_opt = agent.train_model(model=model_td3_opt, tb_log_name='td3',\n",
    "                                total_timesteps=timesteps)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_daily_return_ddpg_opt, df_actions_ddpg_opt = DRLAgent.DRL_prediction(model=trained_ddpg_opt, environment = test_opt_env)\n",
    "df_daily_return_ppo_opt, df_actions_ppo_opt = DRLAgent.DRL_prediction(model=trained_ppo_opt, environment = test_opt_env)\n",
    "\n",
    "df_daily_return_td3_opt, df_actions_td3_opt = DRLAgent.DRL_prediction(model=trained_td3_opt, environment = test_opt_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8c8f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily_return_ddpg_opt.to_csv(\"results/ddpg_Opt_performance.csv\", index=False)\n",
    "df_actions_ddpg_opt.to_csv(\"results/ddpg_Opt_actions.csv\", index=False)\n",
    "\n",
    "df_daily_return_ppo_opt.to_csv(\"results/ppo_Opt_performance.csv\", index=False)\n",
    "df_actions_ppo_opt.to_csv(\"results/ppo_Opt_actions.csv\", index=False)\n",
    "\n",
    "df_daily_return_td3_opt.to_csv(\"results/td3_Opt_performance.csv\", index=False)\n",
    "df_actions_td3_opt.to_csv(\"results/td3_Opt_actions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8028bd63",
   "metadata": {
    "papermill": {
     "duration": 0.040717,
     "end_time": "2025-12-25T11:50:22.725845",
     "exception": false,
     "start_time": "2025-12-25T11:50:22.685128",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 6. Baseines (DJI Buy & Hold, 1/N, MVO mit max. SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50dea84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T11:50:22.808116Z",
     "iopub.status.busy": "2025-12-25T11:50:22.807848Z",
     "iopub.status.idle": "2025-12-25T11:50:23.171044Z",
     "shell.execute_reply": "2025-12-25T11:50:23.170416Z"
    },
    "papermill": {
     "duration": 0.405635,
     "end_time": "2025-12-25T11:50:23.172244",
     "exception": false,
     "start_time": "2025-12-25T11:50:22.766609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "baseline_df = get_baseline(\n",
    "        ticker=\"^DJI\", \n",
    "        start = trade_start_date,\n",
    "        end =  trade_end_date)\n",
    "\n",
    "baseline_returns = get_daily_return(baseline_df, value_col_name=\"close\")\n",
    "baseline_returns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ff2c05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T11:50:23.256930Z",
     "iopub.status.busy": "2025-12-25T11:50:23.256330Z",
     "iopub.status.idle": "2025-12-25T11:50:24.534198Z",
     "shell.execute_reply": "2025-12-25T11:50:24.533488Z"
    },
    "papermill": {
     "duration": 1.320683,
     "end_time": "2025-12-25T11:50:24.535366",
     "exception": false,
     "start_time": "2025-12-25T11:50:23.214683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MARKOWITZ_LOOKBACK = 252\n",
    "MARKOWITZ_TXN_COST = 0.001\n",
    "MARKOWITZ_REBAL_FREQ = \"QS\"\n",
    "\n",
    "prices_all = (\n",
    "    df.pivot_table(index=\"date\", columns=\"tic\", values=\"close\")\n",
    "      .sort_index()\n",
    "      .ffill()\n",
    ")\n",
    "prices_all.index = pd.to_datetime(prices_all.index)\n",
    "prices_trade = prices_all.loc[trade_start_date:trade_end_date]\n",
    "\n",
    "prices_trade = prices_trade.dropna(axis=1, how=\"all\")\n",
    "\n",
    "\n",
    "def run_markowitz_rolling_portfolio(\n",
    "    prices_trade_period: pd.DataFrame,\n",
    "    prices_full_history: pd.DataFrame,\n",
    "    initial_capital: float,\n",
    "    lookback_days: int = MARKOWITZ_LOOKBACK,\n",
    "    transaction_cost: float = MARKOWITZ_TXN_COST,\n",
    "    rebalance_frequency: str = MARKOWITZ_REBAL_FREQ,\n",
    "):\n",
    "\n",
    "    returns_trade = prices_trade_period.pct_change().dropna(how=\"all\")\n",
    "    if returns_trade.empty:\n",
    "        raise ValueError(\"Keine Handelsdaten für den angegebenen Zeitraum.\")\n",
    "    \n",
    "    rebal_dates = (\n",
    "        returns_trade.index.to_series()\n",
    "        .resample(rebalance_frequency)\n",
    "        .first()\n",
    "        .dropna()\n",
    "        .tolist()\n",
    "    )\n",
    "    \n",
    "    first_trade_day = returns_trade.index[0]\n",
    "    if not rebal_dates or first_trade_day < rebal_dates[0]:\n",
    "        rebal_dates.insert(0, first_trade_day)\n",
    "    \n",
    "    rebal_dates = [d for d in rebal_dates if d <= returns_trade.index[-1]]\n",
    "    rebal_dates = sorted(set(rebal_dates))\n",
    "    \n",
    "    portfolio_value = initial_capital\n",
    "    prev_weights = pd.Series(0.0, index=prices_trade_period.columns)\n",
    "    \n",
    "    value_records = []\n",
    "    rebalancing_records = []\n",
    "    \n",
    "    for idx, rebal_date in enumerate(rebal_dates):\n",
    "\n",
    "        hist_end_date = rebal_date - pd.Timedelta(days=1)\n",
    "        hist_window = prices_full_history.loc[:hist_end_date, prices_trade_period.columns].tail(lookback_days)\n",
    "        \n",
    "       \n",
    "        \n",
    "        # Mean-Variance-Optimierung mit pypfopt\n",
    "        try:\n",
    "            mu = expected_returns.mean_historical_return(hist_window, frequency=252)\n",
    "            S = risk_models.sample_cov(hist_window, frequency=252)\n",
    "            ef = EfficientFrontier(mu, S)\n",
    "            ef.max_sharpe()  # Portfolio mit maximaler Sharpe Ratio\n",
    "            weights_dict = ef.clean_weights()\n",
    "            weights = pd.Series(weights_dict)\n",
    "        except Exception as e:\n",
    "            print(f\"[Fehler] Optimierung fehlgeschlagen für {rebal_date.date()}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        weights = weights.reindex(prices_trade_period.columns).fillna(0.0)\n",
    "        \n",
    "        \n",
    "        # Transaktionskosten berechnen \n",
    "        turnover = (weights - prev_weights).abs().sum()\n",
    "        txn_cost_value = turnover * transaction_cost * portfolio_value\n",
    "        portfolio_value -= txn_cost_value\n",
    "        \n",
    "        prev_weights = weights.copy()\n",
    "        \n",
    "        rebalancing_records.append({\n",
    "            \"date\": rebal_date,\n",
    "            \"transaction_cost\": txn_cost_value,\n",
    "            \"turnover\": turnover,\n",
    "            \"portfolio_value_after_costs\": portfolio_value,\n",
    "            **weights.to_dict(),\n",
    "        })\n",
    "        \n",
    "        if idx < len(rebal_dates) - 1:\n",
    "            period_mask = (returns_trade.index >= rebal_date) & (returns_trade.index < rebal_dates[idx + 1])\n",
    "        else:\n",
    "            period_mask = returns_trade.index >= rebal_date\n",
    "        \n",
    "        period_rets = returns_trade.loc[period_mask]\n",
    "        \n",
    "        if period_rets.empty:\n",
    "            continue\n",
    "     \n",
    "        portfolio_daily_returns = (period_rets * weights).sum(axis=1)\n",
    "        \n",
    "        cumulative_factors = (1 + portfolio_daily_returns).cumprod()\n",
    "        portfolio_values = portfolio_value * cumulative_factors\n",
    "        \n",
    "        portfolio_value = portfolio_values.iloc[-1]\n",
    "        \n",
    "        for dt, daily_ret, pv in zip(period_rets.index, portfolio_daily_returns, portfolio_values):\n",
    "            value_records.append({\n",
    "                \"date\": dt,\n",
    "                \"daily_return\": daily_ret,\n",
    "                \"portfolio_value\": pv,\n",
    "            })\n",
    "    \n",
    "    df_portfolio = pd.DataFrame(value_records)\n",
    "    df_rebal = pd.DataFrame(rebalancing_records)\n",
    "    \n",
    "    if not df_portfolio.empty:\n",
    "        df_portfolio[\"date\"] = pd.to_datetime(df_portfolio[\"date\"])\n",
    "        df_portfolio.sort_values(\"date\", inplace=True)\n",
    "    \n",
    "    if not df_rebal.empty:\n",
    "        df_rebal[\"date\"] = pd.to_datetime(df_rebal[\"date\"])\n",
    "        df_rebal.sort_values(\"date\", inplace=True)\n",
    "    \n",
    "    return df_portfolio, df_rebal\n",
    "\n",
    "\n",
    "df_markowitz_portfolio, df_markowitz_rebalancing = run_markowitz_rolling_portfolio(\n",
    "    prices_trade_period=prices_trade,\n",
    "    prices_full_history=prices_all,\n",
    "    initial_capital=initial_capital,\n",
    ")\n",
    "\n",
    "df_markowitz_export = df_markowitz_portfolio[[\"date\", \"daily_return\"]].copy()\n",
    "df_markowitz_export.columns = [\"Datum\", \"daily_return\"]\n",
    "df_markowitz_export[\"Modell\"] = \"MARKOWITZ\"\n",
    "df_markowitz_export.to_csv(\"results/markowitz_daily_returns.csv\", index=False)\n",
    "print(f\"Markowitz Daily Returns: results/markowitz_daily_returns.csv ({len(df_markowitz_export)} Tage)\")\n",
    "\n",
    "if not df_markowitz_rebalancing.empty:\n",
    "    stock_names = prices_trade.columns.tolist()\n",
    "    markowitz_allocations = []\n",
    "    rebal_sorted = df_markowitz_rebalancing.sort_values('date').reset_index(drop=True)\n",
    "    \n",
    "    for idx, row in df_markowitz_portfolio.iterrows():\n",
    "        current_date = pd.to_datetime(row['date'])\n",
    "        rebal_before = rebal_sorted[rebal_sorted['date'] <= current_date]\n",
    "        \n",
    "        if not rebal_before.empty:\n",
    "            latest_rebal = rebal_before.iloc[-1]\n",
    "            record = {'Datum': current_date.strftime('%Y-%m-%d'), 'Modell': 'MARKOWITZ'}\n",
    "            for stock in stock_names:\n",
    "                record[stock] = latest_rebal[stock] if stock in latest_rebal else 0.0\n",
    "            markowitz_allocations.append(record)\n",
    "    \n",
    "    if markowitz_allocations:\n",
    "        df_markowitz_alloc = pd.DataFrame(markowitz_allocations)\n",
    "        df_markowitz_alloc.to_csv(\"results/markowitz_asset_allocation.csv\", index=False)\n",
    "        print(f\"Markowitz Asset Allocation: results/markowitz_asset_allocation.csv ({len(df_markowitz_alloc)} Tage)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc4e09e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T11:50:24.630720Z",
     "iopub.status.busy": "2025-12-25T11:50:24.630443Z",
     "iopub.status.idle": "2025-12-25T11:50:24.730596Z",
     "shell.execute_reply": "2025-12-25T11:50:24.729620Z"
    },
    "papermill": {
     "duration": 0.148689,
     "end_time": "2025-12-25T11:50:24.731873",
     "exception": false,
     "start_time": "2025-12-25T11:50:24.583184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "returns_trade = prices_trade.pct_change().dropna(how=\"all\")\n",
    "\n",
    "n_stocks = len(prices_trade.columns)\n",
    "equal_weights = pd.Series(1.0 / n_stocks, index=prices_trade.columns)\n",
    "\n",
    "equal_weight_returns = (returns_trade * equal_weights).sum(axis=1)\n",
    "\n",
    "initial_value = initial_capital\n",
    "equal_weight_values = initial_value * (1 + equal_weight_returns).cumprod()\n",
    "\n",
    "df_equal_weight = pd.DataFrame({\n",
    "    \"date\": equal_weight_returns.index,\n",
    "    \"daily_return\": equal_weight_returns.values,\n",
    "    \"portfolio_value\": equal_weight_values.values\n",
    "})\n",
    "\n",
    "df_equal_export = df_equal_weight[[\"date\", \"daily_return\"]].copy()\n",
    "df_equal_export.columns = [\"Datum\", \"daily_return\"]\n",
    "df_equal_export[\"Modell\"] = \"EQUAL_WEIGHT\"\n",
    "df_equal_export.to_csv(\"results/equal_weight_daily_returns.csv\", index=False)\n",
    "print(f\"💾 Equal-Weight Daily Returns: results/equal_weight_daily_returns.csv ({len(df_equal_export)} Tage)\")\n",
    "\n",
    "stock_names = prices_trade.columns.tolist()\n",
    "n_stocks = len(stock_names)\n",
    "equal_weight = 1.0 / n_stocks\n",
    "equal_allocations = []\n",
    "\n",
    "for idx, row in df_equal_weight.iterrows():\n",
    "    current_date = pd.to_datetime(row['date'])\n",
    "    record = {'Datum': current_date.strftime('%Y-%m-%d'), 'Modell': 'EQUAL_WEIGHT'}\n",
    "    for stock in stock_names:\n",
    "        record[stock] = equal_weight\n",
    "    equal_allocations.append(record)\n",
    "\n",
    "if equal_allocations:\n",
    "    df_equal_alloc = pd.DataFrame(equal_allocations)\n",
    "    df_equal_alloc.to_csv(\"results/equal_weight_asset_allocation.csv\", index=False)\n",
    "    print(f\"💾 Equal-Weight Asset Allocation: results/equal_weight_asset_allocation.csv ({len(df_equal_alloc)} Tage)\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2224.605791,
   "end_time": "2025-12-25T11:50:28.214822",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-25T11:13:23.609031",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
